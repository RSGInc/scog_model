{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCOG PA to OD Factors\n",
    "\n",
    "## get PA/AP directional factors by Purpose and Time of Day\n",
    "\n",
    "michael.mccarthy@rsginc.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import openmatrix as omx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqPlot(df, var, query=None):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n",
    "\n",
    "    if query != None:\n",
    "        data = df.query(query)\n",
    "    else: \n",
    "        data = df\n",
    "    \n",
    "    counts = data[var].value_counts()\n",
    "    axes.bar(counts.index, counts.values)\n",
    "    axes.set_title(var)\n",
    "    axes.set_xlabel(var)\n",
    "    axes.set_ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# from Bishoy\n",
    "def GetTripRatesUsingOneVars(hh_df, trips_df, x, groups, cat, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate trip rates per cross-classified hhh\n",
    "    \n",
    "    Parameters:\n",
    "    HTS_df: trip records joined to hh + persons\n",
    "    x: x-class variable no. 1\n",
    "\n",
    "    groups: trip purpose, i.e., hbs, hbw, ... etc.!\n",
    "    cat: usually triprate (continous variable), but if trip, we will report the absolute number of trips (discrete)\n",
    "    \"\"\"\n",
    "    HH_PivotTable = hh_df.groupby([x])['hh_weight'].sum().reset_index()\n",
    "    if groups != \"all\":\n",
    "        trips_df = trips_df[trips_df[\"model_purpose\"] == groups].copy()\n",
    "    else:\n",
    "        trips_df = trips_df.copy()\n",
    "\n",
    "    # Finally, pivot the trips using the defined x and y by summing up the trip_weight\n",
    "    Trip_PivotTable = trips_df.groupby([x])['trip_weight'].sum().reset_index()\n",
    "    \n",
    "    if cat == \"trip\":\n",
    "        result_table=pd.merge(HH_PivotTable, Trip_PivotTable, left_on=x, right_on=x, how='inner')\n",
    "\n",
    "    else:\n",
    "        result_table=pd.merge(HH_PivotTable, Trip_PivotTable, left_on=x, right_on=x, how='inner')\n",
    "        result_table['trips_rate'] = result_table['trip_weight']/result_table['hh_weight']\n",
    "    result_table=result_table.fillna(0)\n",
    "        \n",
    "    return result_table\n",
    "\n",
    "def GetTripRatesUsingTwoVars(hh_df, trips_df, x, y, groups, cat, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate trip rates per cross-classified hhh\n",
    "    \n",
    "    Parameters:\n",
    "    HTS_df: trip records joined to hh + persons\n",
    "    x: x-class variable no. 1\n",
    "    y: x-class variable no. 2, if any!\n",
    "    groups: trip purpose, i.e., hbs, hbw, ... etc.!\n",
    "    cat: usually triprate (continous variable), but if trip, we will report the absolute number of trips (discrete)\n",
    "    \"\"\"\n",
    "   \n",
    "    HH_PivotTable = pd.pivot_table(hh_df, values=\"hh_weight\", index=[y],\n",
    "                        columns=[x], aggfunc=np.sum)     # population\n",
    "    # Filter out the specific trip purpose: ['nhb', 'hbo', 'hbr', 'hbw', 'hbsc', 'hbc']\n",
    "    if groups != \"all\":\n",
    "        trips_df = trips_df[trips_df[\"model_purpose\"] == groups].copy()\n",
    "    else:\n",
    "        trips_df = trips_df.copy()\n",
    "\n",
    "    # Finally, pivot the trips using the defined x and y by summing up the trip_weight\n",
    "    dta = \"trip_weight\"\n",
    "    Trip_PivotTable = pd.pivot_table(trips_df, values=dta, index=[y],\n",
    "                    columns=[x], aggfunc=np.sum)     # population\n",
    "\n",
    "    if cat == \"trip\":\n",
    "        result_table = Trip_PivotTable\n",
    "    else:\n",
    "        result_table = Trip_PivotTable/HH_PivotTable    # get the rates by dividing by the number of hh's in the respective market segment\n",
    "    result_table=result_table.fillna(0)\n",
    "    return result_table\n",
    "\n",
    "def GetTripRatesUsingOneVars_Unweighted(hh_df, trips_df, x, groups, cat, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate trip rates per cross-classified hhh\n",
    "    \n",
    "    Parameters:\n",
    "    HTS_df: trip records joined to hh + persons\n",
    "    x: x-class variable no. 1\n",
    "\n",
    "    groups: trip purpose, i.e., hbs, hbw, ... etc.!\n",
    "    cat: usually triprate (continous variable), but if trip, we will report the absolute number of trips (discrete)\n",
    "    \"\"\"\n",
    "    HH_PivotTable = hh_df.groupby([x])['hh_id'].count().reset_index()\n",
    "    if groups != \"all\":\n",
    "        trips_df = trips_df[trips_df[\"trip_purpose\"] == groups].copy()\n",
    "    else:\n",
    "        trips_df = trips_df.copy()\n",
    "\n",
    "    # Finally, pivot the trips using the defined x and y by summing up the trip_weight\n",
    "    Trip_PivotTable = trips_df.groupby([x])['trip_id'].count().reset_index()\n",
    "    \n",
    "    if cat == \"trip\":\n",
    "        result_table=pd.merge(HH_PivotTable, Trip_PivotTable, left_on=x, right_on=x, how='inner')\n",
    "\n",
    "    else:\n",
    "        result_table=pd.merge(HH_PivotTable, Trip_PivotTable, left_on=x, right_on=x, how='inner')\n",
    "        result_table['trips_rate'] = result_table['trip_id']/result_table['hh_id']\n",
    "    result_table=result_table.fillna(0)\n",
    "        \n",
    "    return result_table\n",
    "\n",
    "def tripQA(trips_df, lookup_pairs, qa_queries):\n",
    "    \"\"\"\n",
    "        Method for decoding survey codes (trip purpose and mode) and run queries (check reported trip duration/speed) and export sample for QA \n",
    "\n",
    "        Parameters:\n",
    "        trips_df: trips dataframe\n",
    "        decode: dict of column, lookup pairs, such as {\"o_purpose_category\": purpose_lookup_dict}\n",
    "            queries use numexpr, column names and operators passsed in one string, such as\n",
    "            df.eval(\"(mode_type == 1 & speed_mph > 4) | (mode_type == 2 & speed_mph > 20) | (speed_mph > 70)\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for dfcol, lookup in lookup_pairs.items():\n",
    "        trips_df[dfcol+\"_decode\"] = trips_df[dfcol].map(lookup)\n",
    "\n",
    "    for dfcol, query in qa_queries.items():\n",
    "        trips_df[dfcol+\"_QA\"] = trips_df.eval(query) # return True/False column\n",
    "\n",
    "    return trips_df\n",
    "\n",
    "def omxtoDataframe(thismatrix,indexmap,corestr):\n",
    "    df = pd.DataFrame(thismatrix, columns=indexmap.keys(), index=indexmap.keys()).reset_index().melt(id_vars='index').rename(columns = {'index':'origin', 'variable':'destination', 'value':corestr})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in survey trips dataset\n",
    "\n",
    "survey_trips = pd.read_csv('SCOG_HTS_trips.csv')\n",
    "ext_trips = pd.read_csv('SCOG_HTS_External_trips.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhb_trips = survey_trips.copy()\n",
    "\n",
    "# recode NHB cat\n",
    "nhb_trips.loc[nhb_trips['model_purpose'].isin(['NHBO','NHBW']),'model_purpose'] = 'NHB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code time of day\n",
    "def codePeriods(data,todPeriods,todStart,todVar):\n",
    "    # data.loc[:, 'start_hour'] = data['trip_start_time'].str[:2].astype(int)\n",
    "    # start HH:MM in hours, plus half of duration in hours \n",
    "    data.loc[:, 'mid_hour'] = np.floor(data['depart_hour'].astype(float) + (data['depart_minute'].astype(float) / 60) + ((data['duration_minutes']/2)/60))\n",
    "    data.loc[:, todVar] = ''\n",
    "    for i in range(len(todPeriods)):\n",
    "        data.loc[:, todVar] = np.where(data['mid_hour'] >= todStart[i],todPeriods[i],data[todVar])\n",
    "\n",
    "todPeriods = [\"OP\",\"AM\",\"OP\",\"PM\",\"OP\"] # Names of TOD periods\n",
    "todStart = [0,7,9,14,17]\n",
    "codePeriods(nhb_trips,todPeriods,todStart,'time_period')\n",
    "codePeriods(ext_trips,todPeriods,todStart,'time_period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag peak hour (4 PM - 1600)\n",
    "#nhb_trips['mid_hour'] = np.floor(nhb_trips['depart_hour'].astype(float) + (nhb_trips['depart_minute'].astype(float) / 60) + ((nhb_trips['duration_minutes']/2)/60))\n",
    "nhb_trips.loc[nhb_trips['depart_hour'] == 16,'peak_hour'] = 1\n",
    "ext_trips.loc[ext_trips['depart_hour'] == 16,'peak_hour'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_by_purp = nhb_trips.groupby(['time_period','model_purpose'])['trip_weight'].sum().reset_index()\n",
    "trips_by_dir = nhb_trips.groupby(['time_period','model_purpose','model_direction'])['trip_weight'].sum().reset_index()\n",
    "trips_PA_PM_Peak = nhb_trips[nhb_trips['peak_hour'] == 1].groupby(['model_purpose','model_direction'])['trip_weight'].sum().reset_index()\n",
    "trips_by_purp.to_csv('weighted_trips_TOD_Purpose.csv')\n",
    "trips_by_dir.to_csv('weighted_trips_TOD_Purpose_PA_AP.csv')\n",
    "trips_PA_PM_Peak.to_csv('weighted_trips_PMPeak_Purpose_PA_AP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Work Trips\n",
    "# survey = residents\n",
    "# market segment = purely directional\n",
    "ext_trips.loc[(ext_trips['model_purpose'].isin(['HBW','NHBW'])) & (ext_trips['work_county'] != 53057) & (ext_trips['market_segment'].isin(['IX','XI'])), 'ext_type'] = \"IX Resident Work\"\n",
    "ext_trips.loc[~(ext_trips['model_purpose'].isin(['HBW','NHBW'])) & (ext_trips['market_segment'].isin(['IX','XI'])), 'ext_type'] = \"IX NonWork\"\n",
    "ext_trips.loc[ext_trips['market_segment'] == \"XX\", 'ext_type'] = \"XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external trips by market\n",
    "\n",
    "trips_by_market = ext_trips.groupby(['time_period','ext_type'])['trip_weight'].sum().reset_index()\n",
    "trips_by_market.to_csv('weighted_trips_TOD_External.csv')\n",
    "\n",
    "trips_by_market_PMPK = ext_trips[ext_trips['peak_hour'] == 1].groupby(['ext_type'])['trip_weight'].sum().reset_index()\n",
    "trips_by_market_PMPK.to_csv('weighted_trips_TOD_External_PMPK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external vehicle to person factors\n",
    "ext_trips.loc[((ext_trips['mode_type'] == 8) & (ext_trips['driver'] == 1)) | (ext_trips['mode_type'].isin([5,6,9,11])),'veh_trip_weight'] = ext_trips['trip_weight']\n",
    "ext_trips['veh_trip_weight'] = ext_trips['veh_trip_weight'].fillna(0)\n",
    "\n",
    "ext_trips_auto = ext_trips.groupby(['ext_type'])[['trip_weight','veh_trip_weight']].sum().reset_index()\n",
    "ext_trips_auto['factor'] = ext_trips_auto['trip_weight'] / ext_trips_auto['veh_trip_weight'] # person trips per veh trip\n",
    "ext_trips_auto.to_csv('AutoVehicleTripFactors_EXT.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# External trip Auto occupancy\n",
    "ext_trips.loc[(ext_trips['mode_type'] == 8),'auto_trip_weight'] = ext_trips['trip_weight']\n",
    "ext_trips.loc[((ext_trips['mode_type'] == 8) & (ext_trips['driver'] == 1)),'driver_trip_weight'] = ext_trips['trip_weight']\n",
    "ext_auto_occ = ext_trips.groupby('ext_type')[['auto_trip_weight','driver_trip_weight']].sum().reset_index()\n",
    "ext_auto_occ['factor'] = ext_auto_occ['auto_trip_weight'] / ext_auto_occ['driver_trip_weight']\n",
    "ext_auto_occ.to_csv('auto_occupancy_external.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_county",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trip_weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prop",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "abcaf463-4e4b-428c-b44c-41d38eb54d24",
       "rows": [
        [
         "0",
         "53029.0",
         "2332.941862776242",
         "0.13644150232112912"
        ],
        [
         "1",
         "53033.0",
         "1906.4488827015546",
         "0.11149817053078737"
        ],
        [
         "2",
         "53061.0",
         "8534.282771719762",
         "0.49912532377514174"
        ],
        [
         "3",
         "53073.0",
         "4324.803288528483",
         "0.2529350033729418"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_county</th>\n",
       "      <th>trip_weight</th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53029.0</td>\n",
       "      <td>2332.941863</td>\n",
       "      <td>0.136442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53033.0</td>\n",
       "      <td>1906.448883</td>\n",
       "      <td>0.111498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53061.0</td>\n",
       "      <td>8534.282772</td>\n",
       "      <td>0.499125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53073.0</td>\n",
       "      <td>4324.803289</td>\n",
       "      <td>0.252935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_county  trip_weight      prop\n",
       "0      53029.0  2332.941863  0.136442\n",
       "1      53033.0  1906.448883  0.111498\n",
       "2      53061.0  8534.282772  0.499125\n",
       "3      53073.0  4324.803289  0.252935"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_county = ext_trips[ext_trips['ext_type'] == 'IX Resident Work'].groupby('work_county')['trip_weight'].sum().reset_index()\n",
    "tot_trip_weight = work_county['trip_weight'].sum()\n",
    "work_county['prop'] = work_county['trip_weight'] / tot_trip_weight\n",
    "work_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(25.946821368659347)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weighted avg distance\n",
    "ext_trips['weighted_distance'] = ext_trips['distance_miles'] * ext_trips['trip_weight']\n",
    "ext_trips[ext_trips['ext_type'] == 'IX Resident Work']['weighted_distance'].sum() / ext_trips[ext_trips['ext_type'] == 'IX Resident Work']['trip_weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(37.54373713842383)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_trips[ext_trips['ext_type'] == 'IX NonWork']['weighted_distance'].sum() / ext_trips[ext_trips['ext_type'] == 'IX NonWork']['trip_weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(22.393194883440525)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_trips[ext_trips['ext_type'] == 'XX']['weighted_distance'].sum() / ext_trips[ext_trips['ext_type'] == 'XX']['trip_weight'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scog-taz-census-py-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
